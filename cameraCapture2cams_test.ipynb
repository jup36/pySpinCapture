{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db3ec39-f493-4e53-a007-d6ae0e135915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jason Keller\n",
    "# Feb 2021\n",
    "# =============================================================================\n",
    "#  Program to set BlackFly S camera settings and acquire frames from 2 synchronized cameras and \n",
    "#  write them to a compressed video file. Based on FLIR Spinnaker API example code. I have \n",
    "#  also tested with a Flea3 camera, which works but requires modifying the camera\n",
    "#  settings section to use non \"Quickspin\" functions (see FLIR examples). \n",
    "# \n",
    "#  The intent is that this program started first, then will wait for triggers\n",
    "#  on Line 0 (OPTO_IN) from the DAQ system. It is assumed that the DAQ system will provide\n",
    "#  a specified number of triggers, and that the Line 0 black wires of both cameras are\n",
    "#  soldered together and driven simultaneously. Both cameras output their \"exposure active\"\n",
    "#  signal on Line 1 (OPTO_OUT, the white wire, which is pulled up to 3.3V via a 1.8kOhm resistor \n",
    "#  for each camera) so that each frame can be synchronized (DAQ should sample this at ~1kHz+).\n",
    "#\n",
    "#  Tkinter is used to provide a simple GUI to display the images, and skvideo \n",
    "#  is used as a wrapper to ffmpeg to write H.264 compressed video quickly, using\n",
    "#  mostly default parameters (although I tried pix_fmt gray to reduce size further,\n",
    "#  but default worked better)\n",
    "#\n",
    "#  To setup, you must download an FFMPEG executable and set an environment \n",
    "#  variable path to it (as well as setFFmpegPath function below). Other nonstandard\n",
    "#  dependencies are the FLIR Spinnaker camera driver and PySpin package (see \n",
    "#  Spinnaker downloads), and the skvideo package. \n",
    "#  \n",
    "#  NOTE: currently there is no check to see if readout can keep up with triggering\n",
    "#  other that a timeout warning. It is up to the user to determine if the correct number\n",
    "#  of frames are captured. Also, the \"ffmpegThreads\" parameter can throttle CPU usage\n",
    "#  by FFMPEG to allow other data acquistion task priority. For example, with an Intel Xeon\n",
    "#  W-2145 processor and 4 threads, CPU usage is limited to ~50-60% @ 500Hz, 320x240px,\n",
    "#  and compressed writing is close to real-time.\n",
    "#\n",
    "# TO DO:\n",
    "# (1) report potential # missed frames (maybe use counter to count Line 1 edges and write to video file)\n",
    "# (2) try using ImageEvent instead of blocking GetNextImage(timeout) call\n",
    "# (3) explicitly setup camera onboard buffer\n",
    "# (4) use multiprocess or other package to implement better parallel processing\n",
    "# (5) try FFMPEG GPU acceleration: https://developer.nvidia.com/ffmpeg\n",
    "# =============================================================================\n",
    "\n",
    "import PySpin, time, os, threading, queue\n",
    "from datetime import datetime\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import skvideo\n",
    "skvideo.setFFmpegPath(r'C:\\Users\\mouse1\\anaconda3\\envs\\behvid\\Lib\\site-packages\\ffmpeg\\6.0\\bin') #set path to ffmpeg installation before importing io\n",
    "import skvideo.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b5ed59-6f5a-4ff9-9a50-e3f86d540388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "SAVE_FOLDER_ROOT = 'C:/video'\n",
    "FILENAME_ROOT = 'jp_' # optional identifier\n",
    "EXPOSURE_TIME = 500 #in microseconds\n",
    "WAIT_TIME = 0.0001 #in seconds - this limits polling time and should be less than the frame rate period \n",
    "GAIN_VALUE = 0 #in dB, 0-40;\n",
    "GAMMA_VALUE = 0.4 #0.25-1\n",
    "IMAGE_HEIGHT = 360  #540 pixels default; this should be divisible by 16 for H264 compressed encoding\n",
    "IMAGE_WIDTH = 480 #720 pixels default; this should be divisible by 16 for H264 compressed encoding\n",
    "HEIGHT_OFFSET = 72 #round((540-IMAGE_HEIGHT)/2) # Y, to keep in middle of sensor; must be divisible by 4\n",
    "WIDTH_OFFSET = 160# round((720-IMAGE_WIDTH)/2) # X, to keep in middle of sensor; must be divisible by 4\n",
    "FRAMES_PER_SECOND = 250 #this is determined by triggers sent from behavior controller\n",
    "FRAMES_TO_RECORD = 600*FRAMES_PER_SECOND #frame rate * num seconds to record; this should match # expected exposure triggers from DAQ counter output\n",
    "CAM_TIMEOUT = 1000 #in ms; time to wait for another image before aborting\n",
    "#FRAME_RATE_OUT = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38fbce2-8554-455e-95b1-5f0495f6ee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter mouse ID:  test_00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video will be saved to: ['C:/video/2021_02_test/test_00_2023_05_11_14_16_51.mp4']\n",
      "# frames = 150000\n"
     ]
    }
   ],
   "source": [
    "# generate output video directory and filename and make sure not overwriting\n",
    "now = datetime.now()\n",
    "mouseStr = input(\"Enter mouse ID: \") \n",
    "#groupStr = 'test_'\n",
    "folderStr = '2021_02_test'\n",
    "dateStr = now.strftime(\"_%Y_%m_%d\") #save folder ex: 2020_01_01\n",
    "timeStr = now.strftime(\"_%H_%M_%S\") #filename ex: mj_09_30_59.mp4\n",
    "#saveFolder = SAVE_FOLDER_ROOT + '/' + dateStr\n",
    "saveFolder = SAVE_FOLDER_ROOT + '/' + folderStr\n",
    "if not os.path.exists(saveFolder):\n",
    "    os.mkdir(saveFolder)\n",
    "os.chdir(saveFolder)\n",
    "#movieName = FILENAME_ROOT + timeStr + '_' + groupStr + mouseStr + '.mp4'\n",
    "movieName =  mouseStr + dateStr + timeStr + '.mp4'\n",
    "fullFilePath = [saveFolder + '/' + movieName]\n",
    "print('Video will be saved to: {}'.format(fullFilePath))\n",
    "# get frame rate and query for video length based on this\n",
    "print('# frames = {:d}'.format(FRAMES_TO_RECORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b33357f-9efb-47bf-b2e1-9d1918acaebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP FUNCTIONS #############################################################################################################\n",
    "def initCam(cam): #function to initialize camera parameters for synchronized capture\n",
    "    cam.Init()\n",
    "    # load default configuration\n",
    "    cam.UserSetSelector.SetValue(PySpin.UserSetSelector_Default)\n",
    "    cam.UserSetLoad()\n",
    "    # set acquisition. Continues acquisition. Auto exposure off. Set frame rate using exposure time. \n",
    "    cam.AcquisitionMode.SetValue(PySpin.AcquisitionMode_Continuous)\n",
    "    cam.ExposureAuto.SetValue(PySpin.ExposureAuto_Off)\n",
    "    cam.ExposureMode.SetValue(PySpin.ExposureMode_Timed) #Timed or TriggerWidth (must comment out trigger parameters other that Line)\n",
    "    cam.ExposureTime.SetValue(EXPOSURE_TIME)\n",
    "    cam.AcquisitionFrameRateEnable.SetValue(False)\n",
    "    # set analog. Set Gain + Gamma. \n",
    "    cam.GainAuto.SetValue(PySpin.GainAuto_Off)\n",
    "    cam.Gain.SetValue(GAIN_VALUE)\n",
    "    cam.GammaEnable.SetValue(True)\n",
    "    cam.Gamma.SetValue(GAMMA_VALUE)\n",
    "    # set ADC bit depth and image pixel depth, size\n",
    "    cam.AdcBitDepth.SetValue(PySpin.AdcBitDepth_Bit10)\n",
    "    cam.PixelFormat.SetValue(PySpin.PixelFormat_Mono8)\n",
    "    cam.Width.SetValue(IMAGE_WIDTH)\n",
    "    cam.Height.SetValue(IMAGE_HEIGHT)\n",
    "    cam.OffsetX.SetValue(WIDTH_OFFSET)\n",
    "    cam.OffsetY.SetValue(HEIGHT_OFFSET)\n",
    "    # setup FIFO buffer\n",
    "    camTransferLayerStream = cam.GetTLStreamNodeMap()\n",
    "    handling_mode1 = PySpin.CEnumerationPtr(camTransferLayerStream.GetNode('StreamBufferHandlingMode'))\n",
    "    handling_mode_entry = handling_mode1.GetEntryByName('OldestFirst')\n",
    "    handling_mode1.SetIntValue(handling_mode_entry.GetValue())\n",
    "    # set trigger input to Line0 (the black wire)\n",
    "    #cam.TriggerMode.SetValue(PySpin.TriggerMode_On)\n",
    "    #cam.TriggerOverlap.SetValue(PySpin.TriggerOverlap_ReadOut) #Off or ReadOut to speed up\n",
    "    #cam.TriggerSource.SetValue(PySpin.TriggerSource_Line0)\n",
    "    #cam.TriggerActivation.SetValue(PySpin.TriggerActivation_RisingEdge) #LevelHigh or RisingEdge\n",
    "    #cam.TriggerSelector.SetValue(PySpin.TriggerSelector_FrameStart) # require trigger for each frame\n",
    "    # optionally send exposure active signal on Line 2 (the white wire)\n",
    "    #cam.LineSelector.SetValue(PySpin.LineSelector_Line1)\n",
    "    #cam.LineMode.SetValue(PySpin.LineMode_Output) \n",
    "    #cam.LineSource.SetValue(PySpin.LineSource_ExposureActive) #route desired output to Line 1 (try Counter0Active or ExposureActive)\n",
    "    #cam.LineSelector.SetValue(PySpin.LineSelector_Line2)\n",
    "    #cam.V3_3Enable.SetValue(True) #enable 3.3V rail on Line 2 (red wire) to act as a pull up for ExposureActive - this does not seem to be necessary as long as a pull up resistor is installed between the physical lines, and actually degrades signal quality \n",
    "    \n",
    "def saveImage(imageWriteQueue, writer): #function to save video frames from the queue in a separate process\n",
    "    while True:\n",
    "        dequeuedImage = imageWriteQueue.get()\n",
    "        if dequeuedImage is None:\n",
    "            break\n",
    "        else:\n",
    "            writer.writeFrame(dequeuedImage) #call to ffmpeg\n",
    "            imageWriteQueue.task_done()\n",
    "                      \n",
    "def camCapture(camQueue, cam, k): #function to capture images, convert to numpy, send to queue, and release from buffer in separate process\n",
    "    while True:\n",
    "        if k == 0: #wait infinitely for trigger for first image\n",
    "            image = cam.GetNextImage() #get pointer to next image in camera buffer; blocks until image arrives via USB, within infinite timeout for first frame while waiting for DAQ to start sending triggers    \n",
    "        elif (k) == (FRAMES_TO_RECORD):\n",
    "            print('cam done ')\n",
    "            break #stop loop and function when expected # frames found\n",
    "        else:\n",
    "            try:\n",
    "                image = cam.GetNextImage(CAM_TIMEOUT) #get pointer to next image in camera buffer; blocks until image arrives via USB, within CAM_TIMEOUT\n",
    "            except: #PySpin will throw an exception upon timeout, so end gracefully\n",
    "                print('WARNING: timeout waiting for trigger! Aborting...press Ctrl-C to stop')\n",
    "                print(str(k) + ' frames captured')\n",
    "                break\n",
    "                    \n",
    "        npImage = np.array(image.GetData(), dtype=\"uint8\").reshape( (image.GetHeight(), image.GetWidth()) ); #convert PySpin ImagePtr into numpy array; use uint8 for Mono8 images, uint16 for Mono16\n",
    "        camQueue.put(npImage)  \n",
    "        image.Release() #release from camera buffer\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f642691e-63f1-4043-83fb-2b3bf9c5fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE CAMERAS & COMPRESSION ###########################################################################################\n",
    "system = PySpin.System.GetInstance() # Get camera system\n",
    "cam_list = system.GetCameras() # Get camera list\n",
    "cam1 = cam_list[0]\n",
    "cam2 = cam_list[1]\n",
    "initCam(cam1) \n",
    "initCam(cam2) \n",
    " \n",
    "# setup output video file parameters (can try H265 in future for better compression):  \n",
    "# for some reason FFMPEG takes exponentially longer to write at nonstandard frame rates, so just use default 25fps and change elsewhere if needed\n",
    "crfOut = 21 #controls tradeoff between quality and storage, see https://trac.ffmpeg.org/wiki/Encode/H.264 \n",
    "ffmpegThreads = 4 #this controls tradeoff between CPU usage and memory usage; video writes can take a long time if this value is low\n",
    "#crfOut = 18 #this should look nearly lossless\n",
    "#writer = skvideo.io.FFmpegWriter(movieName, outputdict={'-r': str(FRAME_RATE_OUT), '-vcodec': 'libx264', '-crf': str(crfOut)}) # with frame rate\n",
    "writer = skvideo.io.FFmpegWriter(movieName, outputdict={'-vcodec': 'libx264', '-crf': str(crfOut), '-threads': str(ffmpegThreads)})\n",
    "\n",
    "#setup tkinter GUI (non-blocking, i.e. without mainloop) to output images to screen quickly\n",
    "window = tk.Tk()\n",
    "window.title(\"camera acquisition\")\n",
    "geomStrWidth = str(IMAGE_WIDTH*2 + 25)\n",
    "geomStrHeight = str(IMAGE_HEIGHT + 35)\n",
    "window.geometry(geomStrWidth + 'x' + geomStrHeight) # 2x width+25 x height+35; large enough for frames from 2 cameras + text\n",
    "#textlbl = tk.Label(window, text=\"elapsed time: \")\n",
    "textlbl = tk.Label(window, text=\"waiting for trigger...\")\n",
    "textlbl.grid(column=0, row=0)\n",
    "imglabel = tk.Label(window) # make Label widget to hold image\n",
    "imglabel.place(x=10, y=20) #pixels from top-left\n",
    "window.update() #update TCL tasks to make window appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac5b01-5f6b-40f6-9f22-d3c0a05cea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Ctrl-C to exit early and save video\n",
      "Capture begins\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# start main program loop ###################################################\n",
    "#############################################################################    \n",
    "\n",
    "try:\n",
    "    print('Press Ctrl-C to exit early and save video')\n",
    "    i = 0\n",
    "    imageWriteQueue = queue.Queue() #queue to pass images captures to separate compress and save thread\n",
    "    cam1Queue = queue.Queue()  #queue to pass images from separate cam1 acquisition thread\n",
    "    cam2Queue = queue.Queue()  #queue to pass images from separate cam2 acquisition thread\n",
    "    # setup separate threads to accelerate image acquisition and saving, and start immediately:\n",
    "    saveThread = threading.Thread(target=saveImage, args=(imageWriteQueue, writer,))\n",
    "    cam1Thread = threading.Thread(target=camCapture, args=(cam1Queue, cam1, i,))\n",
    "    cam2Thread = threading.Thread(target=camCapture, args=(cam2Queue, cam2, i,))\n",
    "    saveThread.start()  \n",
    "    \n",
    "    cam1.BeginAcquisition()\n",
    "    cam2.BeginAcquisition()\n",
    "    cam1Thread.start()\n",
    "    cam2Thread.start()   \n",
    "\n",
    "    for i in range(FRAMES_TO_RECORD): # main acquisition loop\n",
    "        camsNotReady = (cam1Queue.empty() or cam2Queue.empty()) # wait for both images ready from parallel threads\n",
    "        while camsNotReady: #wait until ready in a loop\n",
    "            time.sleep(WAIT_TIME)\n",
    "            camsNotReady = (cam1Queue.empty() or cam2Queue.empty()) # wait for both images ready\n",
    "           \n",
    "        if i == 0:\n",
    "            tStart = time.time()\n",
    "            print('Capture begins')\n",
    "        dequeuedAcq1 = cam1Queue.get() # get images formated as numpy from separate process queues as soon as they are both ready\n",
    "        dequeuedAcq2 = cam2Queue.get()\n",
    "        \n",
    "        # now send concatenated image to FFMPEG saving queue\n",
    "        enqueuedImageCombined = np.concatenate((dequeuedAcq1, dequeuedAcq2), axis=1)\n",
    "        imageWriteQueue.put(enqueuedImageCombined) #put next combined image in saving queue\n",
    "        \n",
    "        if (i+1)%20 == 0: #update screen every X frames \n",
    "#            timeElapsed = str(time.time() - tStart)\n",
    "#            timeElapsedStr = \"elapsed time: \" + timeElapsed[0:5] + \" sec\"\n",
    "            framesElapsedStr = \"frame #: \" + str(i+1) + \" of \" + str(FRAMES_TO_RECORD)\n",
    "            textlbl.configure(text=framesElapsedStr)\n",
    "            I = ImageTk.PhotoImage(Image.fromarray(enqueuedImageCombined))\n",
    "            imglabel.configure(image=I)\n",
    "            imglabel.image = I #keep reference to image\n",
    "            window.update() #update on screen (this must be called from main thread)\n",
    "\n",
    "        if (i+1) == (FRAMES_TO_RECORD):\n",
    "            print('Complete ' + str(i+1) + ' frames captured')\n",
    "            tEndAcq = time.time()\n",
    "\n",
    "# end aqcuisition loop #############################################################################################            \n",
    "except KeyboardInterrupt: #if user hits Ctrl-C, everything should end gracefully\n",
    "    tEndAcq = time.time()\n",
    "    pass        \n",
    "        \n",
    "cam1.EndAcquisition() \n",
    "cam2.EndAcquisition()\n",
    "textlbl.configure(text='Capture complete, still writing to disk...') \n",
    "window.update()\n",
    "print('Capture ends at: {:.2f}sec'.format(tEndAcq - tStart))\n",
    "#   print('calculated frame rate: {:.2f}FPS'.format(numImages/(t2 - t1)))\n",
    "imageWriteQueue.join() #wait until compression and saving queue is done writing to disk\n",
    "tEndWrite = time.time()\n",
    "print('File written at: {:.2f}sec'.format(tEndWrite - tStart))\n",
    "writer.close() #close to FFMPEG writer\n",
    "window.destroy() \n",
    "    \n",
    "# delete all pointers/variable/etc:\n",
    "cam1.DeInit()\n",
    "cam2.DeInit()\n",
    "del cam1\n",
    "del cam2\n",
    "cam_list.Clear()\n",
    "del cam_list\n",
    "system.ReleaseInstance()\n",
    "del system\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3287c0-210e-43de-bd70-ecf4ab0e8045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
